# -*- coding: utf-8 -*-
"""COVID19_SentimentAnalysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LkkbuW5F5Jc-smVYuw98MqOgWv0g-WeY

# WELCOME TO THE NOTEBOOK
------------------

### Importing the Modules
"""

import pandas as pd
import numpy as np

import matplotlib.pyplot as plt
import re
import string

import nltk
from nltk.tokenize import sent_tokenize
from nltk.corpus import words
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize
from nltk.stem import WordNetLemmatizer
from nltk.stem import PorterStemmer
from nltk.sentiment.vader import SentimentIntensityAnalyzer
from nltk.sentiment.util import *
nltk.download('stopwords')
nltk.download('vader_lexicon')


from collections import Counter

from matplotlib import pyplot as plt
from matplotlib import ticker
import seaborn as sns
import plotly.express as px

sns.set(style="darkgrid")

"""### Importing the Dataset"""

df = pd.read_csv('https://raw.githubusercontent.com/gabrielpreda/covid-19-tweets/master/covid19_tweets.csv')
df.head()

"""let's check the shape of the dataframe"""

df.shape

"""let's select the needed columns for our project"""

needed_col = ['user_name', 'date', 'text']
df = df[needed_col]
df.head()

"""change the type of some columns"""

df.user_name = df.user_name.astype('category')
df.user_name = df.user_name.cat.codes

df.date = pd.to_datetime(df.date).dt.date
df.head()

"""### Picking out the tweet texts"""

texts = df['text']
texts

"""### Removing URLs from tweets"""

remove_url = lambda x : re.sub(r'https\S+', '', str(x))
texts_lr = texts.apply(remove_url)
texts_lr

"""### Converting all tweets to lowercase"""

to_lower = lambda x : x.lower()
texts_lr_lc = texts_lr.apply(to_lower)
texts_lr_lc

"""### Removing punctuations"""

remove_puncs = lambda x : x.translate(str.maketrans('', '', string.punctuation))
texts_lr_lc_np = texts_lr_lc.apply(remove_puncs)
texts_lr_lc_np

"""### Removing stopwords"""

more_words = ['covid','#coronavirus', '#coronavirusoutbreak', '#coronavirusPandemic', '#covid19', '#covid_19', '#epitwitter', '#ihavecorona', 'amp', 'coronavirus', 'covid19']
stop_words = set(stopwords.words('english'))
stop_words.update(more_words)

remove_words = lambda x : ' '.join([word for word in x.split() if word not in stop_words])
texts_lr_lc_np_ns = texts_lr_lc_np.apply(remove_words)
texts_lr_lc_np_ns

"""### let's create a big list of words out of all the tweets"""

words_list = [word for line in texts_lr_lc_np_ns for word in line.split()]
words_list[:5]

word_counts = Counter(words_list).most_common(50)
words_df = pd.DataFrame(word_counts)
words_df.columns = ['words', 'frq']

px.bar(words_df, x='words', y='frq', title='Most common words')

"""### put the Cleaned text in main dataframe"""

df.text = texts_lr_lc_np_ns
df.head()

"""# Sentiment Analysis

Getting the polarity scores for each tweet
"""

sid = SentimentIntensityAnalyzer()
ps = lambda x : sid.polarity_scores(x)
sentiment_scores = df.text.apply(ps)
sentiment_scores

sentiment_df = pd.DataFrame(data = list(sentiment_scores))
sentiment_df.head()

"""### Labeling the scores based on the compound polarity value"""

labelize = lambda x : 'neutral' if x==0 else ('positive' if x>0 else 'negative')
sentiment_df['label'] = sentiment_df.compound.apply(labelize)
sentiment_df.head()

"""### let's join two dataframes"""

data = df.join(sentiment_df.label)
data.head()

"""### Plotting the sentiment score counts"""

counts_df = data.label.value_counts().reset_index()
counts_df

sns.barplot(x='index', y='label', data=counts_df)

data.head()

data_agg = data[['user_name', 'date', 'label']].groupby(['date', 'label']).count().reset_index()

data_agg.columns = ['date', 'label', 'counts']
data_agg.head()

px.line(data_agg, x='date', y='counts', color='label', title ='Daily Tweets Sentimental Analysis')